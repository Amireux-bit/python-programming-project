import streamlit as st
import time
import sys
import os
import yaml
import json
import pandas as pd
from pathlib import Path
import traceback

# --------- 1. è·¯å¾„è®¾ç½® (æ›´ç¨³å¥çš„å†™æ³•) ---------
# å‡è®¾ app.py ä½äºé¡¹ç›®æ ¹ç›®å½•
# ç›®å½•ç»“æ„:
# project_root/
#   â”œâ”€â”€ app.py
#   â”œâ”€â”€ src/
#   â”‚   â”œâ”€â”€ agent/
#   â”‚   â””â”€â”€ tools/
#   â”œâ”€â”€ logs/
ROOT_DIR = Path(__file__).resolve().parent
SRC_DIR = ROOT_DIR

# å°† src åŠ å…¥ç³»ç»Ÿè·¯å¾„ï¼Œè¿™æ ·æ‰èƒ½ import agent å’Œ tools
if str(SRC_DIR) not in sys.path:
    sys.path.insert(0, str(SRC_DIR))

# --------- å¯¼å…¥è‡ªå®šä¹‰æ¨¡å— ---------
try:
    from agent.controller import TravelAssistantController
    from tools.calculator import CalculatorTool
    # æ³¨æ„ï¼šè¿™é‡Œç›´æ¥å¯¼å…¥ SearchToolï¼Œå› ä¸ºæ–‡ä»¶åæ˜¯ search.py
    from tools.search import SmartSearchTool
    from agent.llm import QwenLLM
except ImportError as e:
    st.error(f"âŒ æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
    st.info("è¯·æ£€æŸ¥ src/ ç›®å½•ä¸‹çš„æ–‡ä»¶ç»“æ„æ˜¯å¦æ­£ç¡®ã€‚")
    st.stop()

# --------- 2. åˆå§‹åŒ–èµ„æº (å¸¦ç¼“å­˜ï¼Œåªè·‘ä¸€æ¬¡) ---------
@st.cache_resource
def get_controller():
    """
    åˆå§‹åŒ– Controllerã€‚
    ä½¿ç”¨ cache_resource è£…é¥°å™¨ï¼Œç¡®ä¿ LLM å’Œå‘é‡åº“åªåŠ è½½ä¸€æ¬¡ï¼Œ
    ä¸ä¼šå› ä¸ºé¡µé¢åˆ·æ–°æˆ–æ–°å¯¹è¯è€Œé‡å¤åŠ è½½ã€‚
    """
    print("ğŸ”„ [System] Initializing Agent Controller...")
    
    # è‡ªåŠ¨å¯»æ‰¾é…ç½®æ–‡ä»¶
    config_path = SRC_DIR / "agent" / "configs" / "baseline.yaml"
    
    if not config_path.exists():
        st.error(f"âŒ æ‰¾ä¸åˆ°é…ç½®æ–‡ä»¶: {config_path}")
        st.stop()
        
    with open(config_path, "r", encoding="utf-8") as f:
        config = yaml.safe_load(f)

    # åˆå§‹åŒ–å·¥å…·
    cal = CalculatorTool()
    search = SmartSearchTool()
    llm = QwenLLM()

    # åˆå§‹åŒ–æ§åˆ¶å™¨
    controller = TravelAssistantController(
        cal_tool=cal,
        search_tool=search,
        config=config,
        llm=llm,
        debug_mode=True,
    )
    print("âœ… [System] Agent Controller Ready.")
    return controller

# === 3. é¡µé¢é…ç½® ===
st.set_page_config(page_title="Agent Chat", page_icon="ğŸ¤–", layout="wide")
st.title("ğŸ¤– Project B: Intelligent Travel Agent")
st.caption("Powered by Hybrid RAG (Local Knowledge + Google Search) & ReAct Pattern")

# === 4. ä¾§è¾¹æ ï¼šå®æ—¶ç›‘æ§é¢æ¿ ===
st.sidebar.title("ğŸ“Š System Monitor")
log_file = ROOT_DIR / "logs" / "tool_metrics.csv" 

# è‡ªåŠ¨åˆ·æ–°æ—¥å¿—æ˜¾ç¤º
if log_file.exists():
    try:
        # è¯»å– CSV
        df = pd.read_csv(log_file)
        st.sidebar.success(f"Log Found: {len(df)} records")
        
        # æ˜¾ç¤ºæœ€æ–°çš„ 5 æ¡æ—¥å¿—
        st.sidebar.subheader("Recent Tool Usage")
        # åªæ˜¾ç¤ºå…³é”®åˆ—
        if all(col in df.columns for col in ["Timestamp", "Tool_Name", "Status", "Latency"]):
            st.sidebar.dataframe(df.tail(5)[["Timestamp", "Tool_Name", "Status", "Latency"]])
        else:
            st.sidebar.dataframe(df.tail(5))
        
        # ç”»ä¸€ä¸ªç®€å•çš„è€—æ—¶ç»Ÿè®¡å›¾
        if "Latency" in df.columns:
            # æ¸…æ´—æ•°æ®ï¼šå»æ‰ 'ms' å•ä½è½¬æˆæ•°å­—
            df["Latency_Val"] = df["Latency"].astype(str).str.replace("ms", "", regex=False)
            df["Latency_Val"] = pd.to_numeric(df["Latency_Val"], errors='coerce').fillna(0)
            
            st.sidebar.subheader("Latency Trend (ms)")
            st.sidebar.line_chart(df["Latency_Val"])
    except Exception as e:
        st.sidebar.error(f"Error reading logs: {e}")
else:
    st.sidebar.warning("No logs found yet. Try running a query.")


# === 5. èŠå¤©ä¸»é€»è¾‘ ===

# åˆå§‹åŒ–èŠå¤©è®°å½•
if "messages" not in st.session_state:
    st.session_state.messages = []

# æ˜¾ç¤ºå†å²æ¶ˆæ¯
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# å¤„ç†ç”¨æˆ·è¾“å…¥
if prompt := st.chat_input("Ask me about travel (e.g. Paris, Singapore) or general questions..."):
    # æ˜¾ç¤ºç”¨æˆ·é—®é¢˜
    with st.chat_message("user"):
        st.markdown(prompt)
    st.session_state.messages.append({"role": "user", "content": prompt})

    # è°ƒç”¨ Agent
    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        full_response = ""
        
        with st.spinner("ğŸ§  Thinking & Searching..."):
            try:
                # è·å–ç¼“å­˜çš„æ§åˆ¶å™¨
                controller = get_controller()
                
                # è¿è¡Œ Agent
                raw_response = controller.run(prompt)
                
                # --- æ ¸å¿ƒæ•°æ®æ¸…æ´—ï¼šå¤„ç†å­—å…¸ç±»å‹ ---
                final_text = ""
                if isinstance(raw_response, dict):
                    # å°è¯•æå–å¸¸è§çš„ key
                    if "output" in raw_response:
                        final_text = raw_response["output"]
                    elif "result" in raw_response:
                        final_text = raw_response["result"]
                    elif "answer" in raw_response:
                        final_text = raw_response["answer"]
                    else:
                        # å…œåº•ï¼šè½¬ JSON å­—ç¬¦ä¸²
                        final_text = json.dumps(raw_response, ensure_ascii=False, indent=2)
                else:
                    # å¦‚æœæœ¬æ¥å°±æ˜¯å­—ç¬¦ä¸²
                    final_text = str(raw_response)
                
                # ğŸ”´ FIX 1: é˜²æ­¢ LaTeX æ•°å­¦å…¬å¼è¯¯ä¼¤ (è§£å†³æ–œä½“ç²˜è¿é—®é¢˜)
                # å°†æ‰€æœ‰çš„ $ ç¬¦å·è½¬ä¹‰ä¸º \$ï¼Œè¿™æ · Streamlit å°±ä¸ä¼šæŠŠå®ƒå½“æˆå…¬å¼æ¸²æŸ“äº†
                final_text = final_text.replace("$", "\$")
                
                # ğŸ”´ FIX 2: é¢„å¤„ç†æ¢è¡Œç¬¦ (è§£å†³åˆ†ç‚¹ç©ºè¡Œé—®é¢˜)
                # Markdown éœ€è¦ä¸¤ä¸ªç©ºæ ¼+æ¢è¡Œï¼Œæˆ–è€…åŒæ¢è¡Œæ‰èƒ½æ­£ç¡®æ˜¾ç¤ºåˆ†æ®µ
                final_text = final_text.replace("\n", "  \n")

                # --- æ‰“å­—æœºæ•ˆæœ (ä½¿ç”¨åˆ‡ç‰‡ï¼Œä¸è¦ç”¨ split) ---
                step = 3  # æ¯æ¬¡æ˜¾ç¤ºå­—ç¬¦æ•°
                for i in range(0, len(final_text), step):
                    # æŒ‰å­—ç¬¦åˆ‡ç‰‡ï¼Œå®Œç¾ä¿ç•™ç©ºæ ¼å’Œæ¢è¡Œ
                    chunk = final_text[i:i+step]
                    full_response += chunk
                    
                    # åˆ·æ–°æ˜¾ç¤º
                    message_placeholder.markdown(full_response + "â–Œ")
                    time.sleep(0.01) 
                
                # æœ€åç§»é™¤å…‰æ ‡
                message_placeholder.markdown(full_response)
                
                # è®°å½•åŠ©æ‰‹å›å¤
                st.session_state.messages.append({"role": "assistant", "content": full_response})
                
            except Exception as e:
                st.error(f"âŒ Agent Runtime Error: {e}")
                traceback.print_exc()